# 小京财智 AI 助手平台 - 面试准备总览

## 📚 文档导航

本项目的面试准备文档包含以下四份核心文档：

### 1. [项目架构文档](./INTERVIEW_01_项目架构.md)
**核心内容**：
- 整体架构设计（三层架构：数据层、引擎层、应用层）
- 技术栈选型（FastAPI、Neo4j、Milvus、React等）
- 核心模块设计（Coordinator、LLMService、RetrievalEngine）
- 数据流转流程
- 设计模式和最佳实践

**面试重点**：
- 为什么选择FastAPI？
- 为什么选择Neo4j作为知识图谱？
- 协同引擎（Coordinator）的设计思路
- RAG技术的实现方式

---

### 2. [模型微调文档](./INTERVIEW_02_模型微调.md)
**核心内容**：
- LoRA微调技术原理和实现
- 训练数据准备（17万条标注数据）
- 辅助小模型（BERT Reranker、NER、XGBoost）
- 模型训练流程和资源需求
- 模型部署和推理优化

**面试重点**：
- LoRA微调的优势和原理
- 为什么选择LoRA而不是全量微调？
- 训练数据如何准备？
- 模型训练需要多少GPU资源？
- 模型如何集成到系统中？

---

### 3. [多Agent协调文档](./INTERVIEW_03_多Agent协调.md)
**核心内容**：
- Agent架构设计（Agent基类、AgentManager）
- 5个预置智能体功能详解
- Agent协调机制和执行流程
- 自定义Agent创建
- Agent与协同引擎的集成

**面试重点**：
- Agent的设计模式（模板方法、策略模式、工厂模式）
- 如何实现多Agent协作？
- Agent如何选择（自动选择策略）？
- 自定义Agent如何创建？

---

### 4. [Langchain使用文档](./INTERVIEW_04_Langchain.md)
**核心内容**：
- Langchain使用情况（当前未使用，但预留接口）
- 为什么选择自定义实现而非Langchain？
- Langchain集成方案（未来）
- Langchain vs 自定义实现对比

**面试重点**：
- 为什么没有使用Langchain？
- 自定义实现相比Langchain的优势？
- 什么场景下适合使用Langchain？
- 如何渐进式集成Langchain？

---

## 🎯 面试常见问题

### 项目架构相关问题

**Q1: 项目的整体架构是什么？**
- **A**: 采用三层架构：数据层（数据采集、清洗、存储）、引擎层（协同引擎、大模型服务、知识检索）、应用层（财报服务、分析服务、报告生成）。详细见[项目架构文档](./INTERVIEW_01_项目架构.md)

**Q2: 为什么选择FastAPI而不是Django？**
- **A**: 
  1. 性能优势：基于Starlette和Pydantic，性能接近Node.js
  2. 异步支持：原生支持async/await，适合AI模型调用
  3. 自动文档：Swagger UI自动生成
  4. 类型安全：基于Pydantic的类型验证

**Q3: 协同引擎（Coordinator）的作用是什么？**
- **A**: 作为系统"大脑"，负责：
  1. 任务拆解：理解用户意图，拆解为子任务
  2. 工具调用：根据任务类型调用相应工具
  3. 上下文管理：维护对话历史和多轮对话
  4. 流程调度：协调各模块完成复杂任务

**Q4: RAG技术是如何实现的？**
- **A**: 
  1. 混合检索：向量检索（Milvus，权重0.7）+ 关键词检索（Neo4j，权重0.3）
  2. 结果合并去重
  3. Reranker重排序：使用BERT Reranker模型，Top10准确率92%
  4. 返回Top-K结果给LLM生成回答

---

### 模型微调相关问题

**Q1: 为什么选择LoRA微调而不是全量微调？**
- **A**:
  1. **参数效率**：只训练1%的参数（6.7亿/670亿），大幅减少显存需求
  2. **训练速度**：训练时间从数周缩短到2.5-3天
  3. **效果接近**：LoRA效果接近全量微调
  4. **易于部署**：只需保存LoRA权重，部署灵活

**Q2: 训练数据如何准备？**
- **A**: 
  - 总数据量：17万条标注数据
  - 来源：财报文本提取、金融知识库、专家标注、数据增强
  - 格式：instruction-input-output三元组
  - 时间：2-3周（标注团队3-5人）

**Q3: 模型训练需要多少GPU资源？**
- **A**:
  - **推荐方案**：DeepSeek-7B + 8张RTX 4090，训练时间2.5天，成本约7,000元
  - **最佳方案**：DeepSeek-67B + 64张RTX 4090，训练时间2.9天，成本约44,000元

**Q4: 模型如何集成到系统中？**
- **A**: 
  - 在`LLMService`中加载LoRA模型
  - 实现模型切换逻辑（API模型 vs 微调模型）
  - 金融领域问题自动使用微调模型
  - 异步推理包装，避免阻塞

---

### Agent相关问题

**Q1: Agent的设计思路是什么？**
- **A**: 
  1. **单一职责**：每个Agent专注于一个业务场景
  2. **知识增强**：每个Agent关联特定的知识库
  3. **统一接口**：所有Agent实现相同的`execute`方法
  4. **可扩展性**：支持自定义Agent创建

**Q2: 如何实现多Agent协作？**
- **A**: 
  - `AgentManager`负责Agent调度
  - 根据用户意图自动选择Agent
  - 支持顺序执行和并行执行
  - 通过上下文传递实现协作

**Q3: Agent如何选择？**
- **A**: 
  1. 关键词匹配（如"波士顿矩阵"→`boston_matrix`）
  2. LLM意图分析（复杂查询使用LLM判断）
  3. 用户手动指定

**Q4: 自定义Agent如何创建？**
- **A**: 
  - 通过API接口创建：`POST /api/v1/agents/create`
  - 配置名称、描述、知识库、能力
  - 系统自动生成Agent类并注册

---

### Langchain相关问题

**Q1: 为什么没有使用Langchain？**
- **A**: 
  1. **性能考虑**：自定义实现性能更好，响应更快
  2. **定制化需求**：金融领域需要深度定制，Langchain通用框架难以满足
  3. **架构设计**：项目采用分层架构，自定义实现更符合架构
  4. **异步支持**：项目大量使用async/await，自定义实现异步支持更好
  5. **预留接口**：已在依赖中添加Langchain，支持未来集成

**Q2: 未来会集成Langchain吗？**
- **A**: 
  - 采用渐进式集成策略
  - 可以在特定场景使用Langchain工具（如文档加载器）
  - 保留自定义架构，混合使用

---

## 💡 项目亮点

### 1. 技术亮点

1. **分层架构设计**：清晰的分层，易于维护和扩展
2. **异步编程**：全面使用async/await，性能优秀
3. **RAG技术**：混合检索 + Reranker重排序，准确率高
4. **LoRA微调**：轻量化微调，成本低效果好
5. **多Agent系统**：灵活的Agent架构，支持自定义

### 2. 业务亮点

1. **金融领域专用**：针对金融场景深度定制
2. **秒级响应**：简单查询≤1秒，复杂分析≤3秒
3. **智能体应用**：覆盖80%以上的金融业务场景
4. **数据集成**：支持42家A股上市银行数据

### 3. 架构亮点

1. **协同引擎**：智能任务调度和流程控制
2. **知识增强**：知识图谱 + 向量数据库混合存储
3. **工具调用**：支持指标计算、图表生成等工具
4. **可扩展性**：支持新增Agent、工具、数据源

---

## 📊 项目数据

### 代码规模

- **后端代码**：72个文件，约7,242行
- **前端代码**：9个JSX/JS文件
- **API接口**：8个主要路由模块
- **核心服务**：8个主要服务模块

### 功能完成度

- **总体完成度**：约78%
- **核心功能**：90%+
- **数据集成**：框架已实现，待数据导入
- **性能优化**：待优化

### 技术栈

- **后端**：FastAPI + Python 3.10+
- **前端**：React + Vite + Ant Design
- **数据库**：Neo4j + Milvus + Redis + SQLite
- **AI模型**：GPT-4 + DeepSeek + LoRA微调

---

## 🎤 面试话术

### 项目介绍（30秒版本）

"小京财智是一个基于大模型+知识增强的智能财报助手平台，采用分层架构设计，包含数据层、引擎层和应用层。核心功能包括智能财报分析、报告生成、智能体应用等。技术栈上使用FastAPI作为后端框架，Neo4j存储知识图谱，Milvus存储向量，实现了RAG检索增强生成。项目支持LoRA微调，针对金融领域进行了深度优化。整体完成度约78%，核心功能已实现。"

### 架构设计亮点（1分钟版本）

"项目采用分层架构，核心是协同引擎（Coordinator），它负责任务拆解、工具调用、上下文管理和流程调度。当用户提问时，协同引擎会先理解意图，然后通过RAG技术检索相关知识，最后调用LLM生成回答。RAG实现上，我们采用混合检索策略，结合向量检索和关键词检索，并使用BERT Reranker重排序，Top10准确率达到92%。知识存储方面，使用Neo4j存储知识图谱，Milvus存储向量，支持高效检索。"

### 模型微调亮点（1分钟版本）

"我们采用LoRA微调技术对DeepSeek模型进行金融领域微调。LoRA的优势是只训练1%的参数，大幅减少显存需求和训练时间。训练数据方面，我们准备了17万条标注数据，包括财报问答对、指标计算示例等。训练资源上，使用8张RTX 4090，训练时间约2.5天，成本约7,000元。模型集成时，我们实现了自动切换逻辑，金融领域问题优先使用微调模型，通用问题使用API模型。"

### Agent系统亮点（1分钟版本）

"我们设计了一个灵活的Agent系统，包含5个预置智能体和自定义Agent功能。每个Agent都继承自基类，实现统一的execute接口，并关联特定的知识库。AgentManager负责Agent的注册、发现和调度。我们实现了自动选择策略，可以根据用户意图自动选择合适的Agent。同时支持多Agent协作，可以顺序执行或并行执行多个Agent完成复杂任务。还支持用户创建自定义Agent，配置知识库和能力。"

---

## 📖 快速查找

### 按技术点查找

- **架构设计** → [项目架构文档](./INTERVIEW_01_项目架构.md) 第3-4章
- **LoRA微调** → [模型微调文档](./INTERVIEW_02_模型微调.md) 第2章
- **RAG技术** → [项目架构文档](./INTERVIEW_01_项目架构.md) 第3.3节
- **Agent设计** → [多Agent协调文档](./INTERVIEW_03_多Agent协调.md) 第1-2章
- **Langchain** → [Langchain使用文档](./INTERVIEW_04_Langchain.md) 第2-3章

### 按面试问题查找

- **"为什么选择XX技术？"** → [项目架构文档](./INTERVIEW_01_项目架构.md) 第6章
- **"模型如何训练？"** → [模型微调文档](./INTERVIEW_02_模型微调.md) 第4章
- **"Agent如何协作？"** → [多Agent协调文档](./INTERVIEW_03_多Agent协调.md) 第3章
- **"为什么不用Langchain？"** → [Langchain使用文档](./INTERVIEW_04_Langchain.md) 第2章

---

## 📝 面试准备清单

### 技术问题准备

- [ ] 项目整体架构和技术选型
- [ ] 协同引擎的设计思路
- [ ] RAG技术的实现方式
- [ ] LoRA微调的原理和优势
- [ ] Agent系统的设计模式
- [ ] 为什么选择自定义实现而非Langchain
- [ ] 性能优化策略
- [ ] 数据集成方案

### 业务问题准备

- [ ] 项目的核心价值
- [ ] 目标用户和应用场景
- [ ] 功能完成情况
- [ ] 开发时间线
- [ ] 项目难点和解决方案

### 代码问题准备

- [ ] 关键模块的代码实现
- [ ] 设计模式的应用
- [ ] 异步编程的使用
- [ ] 错误处理机制

---

## 🔗 相关资源

- **项目仓库**：`git@github.com:zgsddzwj/ZNCBZS.git`
- **详细文档**：`README.md`、`FEATURES.md`
- **需求分析**：`REQUIREMENTS_ANALYSIS.md`
- **开发时间线**：`COMPLETE_DEVELOPMENT_TIMELINE.md`

